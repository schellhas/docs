Lecture 2 - Threads
===================

.. epigraph::

	The purpose of abstraction is not to be vague, but to create a new semantic level in which one can be absolutely precise.

	-- Edsger W. Dijkstra

Thread description
------------------

A **process** or **thread** (more about the distinction later) is represented by a special data structure, the **thread control block (TCB)**, which contains all relevant information about the tread.

For example:

- Thread characteristics
	- Thread ID, name of program
- State information
	- Instruction counter, stack pointer, register contents
- Management data
	- Priority, rights, statistics

In larger systems, there could be thousands of threads running at the same time, which is why efficiency matters. For this efficiency there are different solutions, depending on the type and usage of OS.

Management of thread control block
----------------------------------

How do we save these TCBs? Here are the different data structures we could use.

- Single scalars - Basically not a data structure, we can keep the TCBs scattered in our memory. In an embedded system e.g. we can have the programs loaded in the memory, and at some point theres a place where the TCB is stored. It doesn't have to be assigned beforehand.
- Static long array - In a central location. This makes sense in a static system where we know the amount of threads we want to use.
- Variably long linked list - Better for a dynamic system.
- Tree - We have some possibilities to structure our threads hierarchically here.
- Inverted table - idk, the TBCs are assigned by some attribute and saved in memory centrally.

Management of thread control blocks
-----------------------------------

We can form subsets of threads with regard to important attributes, like state value or priority, in order to access them easier when we want to access them based on an attribute.

Static and dynamic systems
--------------------------

Static operating systems
~~~~~~~~~~~~~~~~~~~~~~~~

All threads are known in advance and are statically defined.
- Each thread is designed in advance and "known".
- Threads are used for specific applications.
- The TCBs are generated by a configuration program once.

Dynamic operating systems
~~~~~~~~~~~~~~~~~~~~~~~~~

The threads are created and deleted by kernel operations.

.. code-block:: c

	create_thread(id, initial_values)
		/* create thread control block */
		/* initialization of thread */
	delete_thread(id, final_values)
		/* return of final values */
		/* deletion of control block */

Threads and Address Spaces
--------------------------

- A (logical) address space of a thread is the universe of its valid addresses, which it can access.
- Modern processors enable not only relative addressing (*basis register*), but also provide a *memory mangement unit (MMU)* for address translation.
- That allows to have an arbitrary number of *logical address spaces* that automatically can be mapped to the physical address space.
- That also leads to mutual protection of address spaces.
- Address spaces are independent (orthogonal) to threads.
- Each thread needs an address space at any time but several relations are possible:
	- A thread owns exactly one private address space (UNIX process).
	- Several threads share an address space (Threads).
	- A thread switches from one address space to another.

Terminology
-----------

Concerning the terminology, care must be taken in the relevant literature:
- A process (task) is mostly considered as a UNIX-type process with a private address space.
- Most operating systems (including current UNIX variants) offer the possibility to run several processes in a shared address sapce.
- They are called *lightweight processes* or *threads*.
- Today's UNIX variants (e.g. Linux, Solaris, ...) offer the original UNIX processes (tasks), that may consist of many threads.
- A UNIX process is therefore an address space, that contains at least one thread.
- For windows the same holds.
- **In this lecture, we use the term "thread".**

Overview of terms used
----------------------

.. list-table:: Overview of terms used
	:header-rows: 1

	* - Operating system
	  - Unit of execution
	  - Superior unit
	* - Mach
	  - thread
	  - task
	* - Chorus
	  - thread
	  - actor
	* - Mayflower
	  - lightweight process
	  - domain
	* - V
	  - thread
	  - team
	* - Amoeba
	  - thread
	  - cluster
	* - Cosy
	  - process
	  - address space
	* - Solaris
	  - thread
	  - process
	* - NT
	  - thread
	  - process

Thread switch
-------------

A **thread switch** happens when the processor stops the execution of one thread and continues with another. A thread switch is the transition form one instruction sequence to another. Slide 3-10 has a nice graphic.

Switching by jumping
--------------------

In the most simple cases the switch can be programmed statically and directly in the threads.

.. warning::
	What? I don't understand. The threads themselves implement the thread switch? I thought the kernel or OS or whatever would do that. Big question mark here.

It means that we insert a jump instruction that jumps into another thread. To continue the work at the point where the thread left off, we have to memorize the position we have to return to. A switching point therefore consists of at least:

- continuation address (where did we interrupt the work)
- jump instruction (where do we want to continue)

More nice graphics on slides 3-11 and 3-12. (Very helpful for understanding)

For certain application areas (real-time systems) the time needed to switch from one thread to another is an important quality measure. This thread switch should be realized efficiently of course. The jump is the "minimal solution".

Switching more general
----------------------

Switching by direct jump is very inflexible and applicable only in very special cases.

In general the thread switch will be more costly since:

- We don't know from where we return to the interrupted thread (memorizing the continuation address)
- The next thread, to which we switch, is not always the same (selection of next thread)
- The processor contains essential parts of the thread description that must not get lost (register reload)

.. note::
	I understand the warning from earlier now, we are starting with a naive approach here. So we think all threads are benevolent and cooperating to switch between each other, and also know where to switch when. I was already thinking about the scheduler doing that, which in this case, "we don't know yet". So yeah, naive approach, the threads switch voluntarily and just jump to another thread and hope they will jump to them, basically.

Memorizing continuation address
-------------------------------

Before switching to the new thread, we store the address of the next instruction to be executed in a dedicated variable ``ni`` (next instruction) of the thread control block (TCB). Nice graphic on slide 3-14.

Switching with variable continuation address
--------------------------------------------

.. warning::
	TODO: slide 3-15

Selection of next thread
------------------------

Up until now we assumed we know the next thread which we want to switch to. However, in most cases this target thread is not cosntant but will be determined at the time of switching:

Criteria for selection:

- number of thread (cyclic switching)
- order of arrival
- priority (urgency)
	- constant
	- dynamic

The selection of the next thread influences the distribution of the processors computing capacity to the threads.
