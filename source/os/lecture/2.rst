Lecture 2 - Threads
===================

.. epigraph::

	The purpose of abstraction is not to be vague, but to create a new semantic level in which one can be absolutely precise.

	-- Edsger W. Dijkstra

Thread description
------------------

A **process** or **thread** (more about the distinction later) is represented by a special data structure, the **thread control block (TCB)**, which contains all relevant information about the tread.

For example:

- Thread characteristics
	- Thread ID, name of program
- State information
	- Instruction counter, stack pointer, register contents
- Management data
	- Priority, rights, statistics

In larger systems, there could be thousands of threads running at the same time, which is why efficiency matters. For this efficiency there are different solutions, depending on the type and usage of OS.

Management of thread control block
----------------------------------

How do we save these TCBs? Here are the different data structures we could use.

- Single scalars - Basically not a data structure, we can keep the TCBs scattered in our memory. In an embedded system e.g. we can have the programs loaded in the memory, and at some point theres a place where the TCB is stored. It doesn't have to be assigned beforehand.
- Static long array - In a central location. This makes sense in a static system where we know the amount of threads we want to use.
- Variably long linked list - Better for a dynamic system.
- Tree - We have some possibilities to structure our threads hierarchically here.
- Inverted table - idk, the TBCs are assigned by some attribute and saved in memory centrally.

Management of thread control blocks
-----------------------------------

We can form subsets of threads with regard to important attributes, like state value or priority, in order to access them easier when we want to access them based on an attribute.

Static and dynamic systems
--------------------------

Static operating systems
~~~~~~~~~~~~~~~~~~~~~~~~

All threads are known in advance and are statically defined.
- Each thread is designed in advance and "known".
- Threads are used for specific applications.
- The TCBs are generated by a configuration program once.

Dynamic operating systems
~~~~~~~~~~~~~~~~~~~~~~~~~

The threads are created and deleted by kernel operations.

.. code-block:: c

	create_thread(id, initial_values)
		/* create thread control block */
		/* initialization of thread */
	delete_thread(id, final_values)
		/* return of final values */
		/* deletion of control block */

Threads and Address Spaces
--------------------------

- A (logical) address space of a thread is the universe of its valid addresses, which it can access.
- Modern processors enable not only relative addressing (*basis register*), but also provide a *memory mangement unit (MMU)* for address translation.
- That allows to have an arbitrary number of *logical address spaces* that automatically can be mapped to the physical address space.
- That also leads to mutual protection of address spaces.
- Address spaces are independent (orthogonal) to threads.
- Each thread needs an address space at any time but several relations are possible:
	- A thread owns exactly one private address space (UNIX process).
	- Several threads share an address space (Threads).
	- A thread switches from one address space to another.

Terminology
~~~~~~~~~~~

Concerning the terminology, care must be taken in the relevant literature:
- A process (task) is mostly considered as a UNIX-type process with a private address space.
- Most operating systems (including current UNIX variants) offer the possibility to run several processes in a shared address sapce.
- They are called *lightweight processes* or *threads*.
- Today's UNIX variants (e.g. Linux, Solaris, ...) offer the original UNIX processes (tasks), that may consist of many threads.
- A UNIX process is therefore an address space, that contains at least one thread.
- For windows the same holds.
- **In this lecture, we use the term "thread".**


